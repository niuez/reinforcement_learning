{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/blog/deep-rl-pg\n",
        "\n",
        "https://colab.research.google.com/github/huggingface/deep-rl-class/blob/main/unit5/unit5.ipynb#scrollTo=NCNvyElRStWG"
      ],
      "metadata": {
        "id": "9Gdd_GeahUR1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJFyOkq2Xvdb",
        "outputId": "b75c1ab5-c89a-4f84-a4b0-3624c0eb4719"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting JSAnimation\n",
            "  Downloading JSAnimation-0.1.tar.gz (8.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: JSAnimation\n",
            "  Building wheel for JSAnimation (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for JSAnimation: filename=JSAnimation-0.1-py3-none-any.whl size=11423 sha256=083b06a5dfe9d5fe6944138266bbc8cdba6ef849e2e1f2d4ca00d2eb6ae10b89\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/78/80/8fa3ee5db5b384c086dcc7e6c4e4e22caae0687a4f71ba08f8\n",
            "Successfully built JSAnimation\n",
            "Installing collected packages: JSAnimation\n",
            "Successfully installed JSAnimation-0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pygame\n",
            "  Downloading pygame-2.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.8/21.8 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pygame\n",
            "Successfully installed pygame-2.1.2\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gym\n",
        "\n",
        "!pip install JSAnimation\n",
        "!pip install pygame\n",
        "\n",
        "from JSAnimation.IPython_display import display_animation\n",
        "from matplotlib import animation\n",
        "from IPython.display import display\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "def display_frames_as_gif(frames):\n",
        "  plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi=72)\n",
        "  patch = plt.imshow(frames[0])\n",
        "  plt.axis('off')\n",
        "  def animate(i):\n",
        "    patch.set_data(frames[i])\n",
        "  anim = animation.FuncAnimation(plt.gcf(), animate, frames=len(frames), interval=50)\n",
        "  anim.save('move_cartpole_DQN.mp4')\n",
        "  #display(display_animation(anim, default_mode='loop'))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ENV = 'CartPole-v0'\n",
        "GAMMA = 0.99\n",
        "MAX_STEPS = 200\n",
        "NUM_EPISODES = 1000"
      ],
      "metadata": {
        "id": "IoVGNGSycv3r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class BrainREINFORCE(nn.Module):\n",
        "  def __init__(self, num_states, num_actions):\n",
        "    super(BrainREINFORCE, self).__init__()\n",
        "    self.fc1 = nn.Linear(num_states, 32)\n",
        "    self.fc2 = nn.Linear(32, num_actions)\n",
        "  \n",
        "  def forward(self, state):\n",
        "    x = F.relu(self.fc1(state))\n",
        "    y = self.fc2(x)\n",
        "    return F.softmax(y, dim=1)\n",
        "\n",
        "  def act(self, state):\n",
        "    probs = self.forward(state.to(device)).cpu()\n",
        "    model = Categorical(probs)\n",
        "    action = model.sample()\n",
        "    return action, model.log_prob(action)"
      ],
      "metadata": {
        "id": "wWB3FugcX_vE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Environment:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.env = gym.make(ENV)  # 実行する課題を設定\n",
        "        self.num_states = self.env.observation_space.shape[0]  # 課題の状態数4を取得\n",
        "        self.num_actions = self.env.action_space.n  # CartPoleの行動（右に左に押す）の2を取得\n",
        "        #self.device = torch.device(\"cpu\")\n",
        "        self.brain = BrainREINFORCE(self.num_states, self.num_actions).to(device)\n",
        "        self.optimizer = optim.Adam(self.brain.parameters(), lr=1e-2)\n",
        "        for param in self.brain.parameters():\n",
        "          print(param)\n",
        "\n",
        "        \n",
        "    def run(self):\n",
        "        '''実行'''\n",
        "        episode_10_list = np.zeros(10)  # 10試行分の立ち続けたstep数を格納し、平均ステップ数を出力に利用\n",
        "        complete_episodes = 0  # 195step以上連続で立ち続けた試行数\n",
        "        episode_final = False  # 最後の試行フラグ\n",
        "        frames = []  # 最後の試行を動画にするために画像を格納する変数\n",
        "\n",
        "        for episode in range(NUM_EPISODES):  # 最大試行数分繰り返す\n",
        "            if episode + 1 == NUM_EPISODES:\n",
        "              episode_final = True\n",
        "            observation = self.env.reset()  # 環境の初期化\n",
        "\n",
        "            state = observation  # 観測をそのまま状態sとして使用\n",
        "            state = torch.from_numpy(state).type(\n",
        "                torch.FloatTensor)  # NumPy変数をPyTorchのテンソルに変換\n",
        "            state = torch.unsqueeze(state, 0)  # size 4をsize 1x4に変換\n",
        "\n",
        "            saved_log_probs = []\n",
        "            rewards = [] \n",
        "            policy_loss = [] \n",
        "\n",
        "            for step in range(MAX_STEPS):  # 1エピソードのループ\n",
        "\n",
        "                if episode_final is True:  # 最終試行ではframesに各時刻の画像を追加していく\n",
        "                    frames.append(self.env.render(mode='rgb_array'))\n",
        "\n",
        "                action, log_prob = self.brain.act(state)\n",
        "\n",
        "                # 行動a_tの実行により、s_{t+1}とdoneフラグを求める\n",
        "                # actionから.item()を指定して、中身を取り出す\n",
        "                observation_next, _, done, _ = self.env.step(\n",
        "                    action.item())  # rewardとinfoは使わないので_にする\n",
        "\n",
        "                # 報酬を与える。さらにepisodeの終了評価と、state_nextを設定する\n",
        "                if done:  # ステップ数が200経過するか、一定角度以上傾くとdoneはtrueになる\n",
        "                    state_next = None  # 次の状態はないので、Noneを格納\n",
        "\n",
        "                    # 直近10episodeの立てたstep数リストに追加\n",
        "                    episode_10_list = np.hstack(\n",
        "                        (episode_10_list[1:], step + 1))\n",
        "\n",
        "                    if step < 195:\n",
        "                        reward = torch.FloatTensor(\n",
        "                            [-1.0])  # 途中でこけたら罰則として報酬-1を与える\n",
        "                        complete_episodes = 0  # 連続成功記録をリセット\n",
        "                    else:\n",
        "                        reward = torch.FloatTensor([1.0])  # 立ったまま終了時は報酬1を与える\n",
        "                        complete_episodes = complete_episodes + 1  # 連続記録を更新\n",
        "                else:\n",
        "                    reward = torch.FloatTensor([0.0])  # 普段は報酬0\n",
        "                    state_next = observation_next  # 観測をそのまま状態とする\n",
        "                    state_next = torch.from_numpy(state_next).type(\n",
        "                        torch.FloatTensor)  # numpy変数をPyTorchのテンソルに変換\n",
        "                    state_next = torch.unsqueeze(state_next, 0)  # size 4をsize 1x4に変換\n",
        "\n",
        "                saved_log_probs.append(log_prob)\n",
        "                rewards.append(reward)\n",
        "\n",
        "                # 観測の更新\n",
        "                state = state_next\n",
        "\n",
        "                # 終了時の処理\n",
        "                if done:\n",
        "                    print('%d Episode: Finished after %d steps：10試行の平均step数 = %.1lf' % (\n",
        "                        episode, step + 1, episode_10_list.mean()))\n",
        "                    break\n",
        "\n",
        "            Gs = []\n",
        "            G = 0\n",
        "            for t in range(len(rewards))[::-1]:\n",
        "              G = G * GAMMA + rewards[t]\n",
        "              Gs.append(G)\n",
        "            Gs.reverse()\n",
        "            eps = np.finfo(np.float32).eps.item()\n",
        "            ## eps is the smallest representable float, which is \n",
        "            # added to the standard deviation of the returns to avoid numerical instabilities        \n",
        "            Gs = torch.tensor(Gs)\n",
        "            Gs = (Gs - Gs.mean()) / (Gs.std() + eps)\n",
        "            for t in range(len(rewards)):\n",
        "              policy_loss.append(-saved_log_probs[t].cpu() * Gs[t].cpu())\n",
        "            \n",
        "            posum = torch.cat(policy_loss).sum()\n",
        "            self.optimizer.zero_grad()\n",
        "            posum.backward()\n",
        "            self.optimizer.step()\n",
        "            policy_loss = []\n",
        "\n",
        "            if episode_final is True:\n",
        "                # 動画を保存と描画\n",
        "                display_frames_as_gif(frames)\n",
        "                break\n",
        "\n",
        "            # 10連続で200step経ち続けたら成功\n",
        "            if complete_episodes >= 10:\n",
        "                print('10回連続成功')\n",
        "                episode_final = True  # 次の試行を描画を行う最終試行とする"
      ],
      "metadata": {
        "id": "cUkNDSYLYBFc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cartpole_env = Environment()\n",
        "cartpole_env.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_0t1bd7wZ12_",
        "outputId": "a5c59d81-bf23-4d16-879e-17082a6bcfc3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.1502, -0.2832, -0.0740, -0.2210],\n",
            "        [ 0.1231,  0.3009, -0.1906, -0.4975],\n",
            "        [-0.0703,  0.4950, -0.3710, -0.0197],\n",
            "        [-0.1337,  0.4933,  0.4469, -0.0445],\n",
            "        [ 0.2968,  0.2675,  0.3761,  0.1883],\n",
            "        [ 0.4301, -0.0639, -0.3559,  0.1947],\n",
            "        [-0.1960, -0.2591, -0.4299, -0.1507],\n",
            "        [ 0.1251, -0.3906,  0.1136, -0.0019],\n",
            "        [ 0.2218,  0.4534, -0.3026, -0.3741],\n",
            "        [ 0.4787, -0.4122,  0.4196, -0.2891],\n",
            "        [-0.2920, -0.1488, -0.2250,  0.1212],\n",
            "        [-0.0485,  0.1282, -0.4965, -0.4490],\n",
            "        [-0.2780,  0.4233,  0.4461, -0.0496],\n",
            "        [-0.3438,  0.4629, -0.1467, -0.0699],\n",
            "        [ 0.1779,  0.1403,  0.2182, -0.4479],\n",
            "        [ 0.2357,  0.2482, -0.2722,  0.4199],\n",
            "        [ 0.4583,  0.2492, -0.2198, -0.1688],\n",
            "        [-0.0988,  0.2104,  0.3038, -0.3742],\n",
            "        [ 0.0153,  0.4515,  0.2011, -0.0533],\n",
            "        [-0.4693, -0.4220, -0.4533, -0.3501],\n",
            "        [ 0.2895, -0.1092,  0.2817, -0.2072],\n",
            "        [-0.0889, -0.4364, -0.0132,  0.3731],\n",
            "        [-0.3858,  0.3037, -0.1640,  0.3759],\n",
            "        [ 0.0640, -0.1549, -0.3696,  0.3631],\n",
            "        [ 0.4195, -0.3012,  0.4445,  0.1688],\n",
            "        [ 0.4293, -0.4148, -0.3660,  0.0848],\n",
            "        [-0.1180, -0.0962,  0.3371, -0.4043],\n",
            "        [ 0.1798, -0.0087, -0.3443, -0.2708],\n",
            "        [-0.0706,  0.0967, -0.2730, -0.0078],\n",
            "        [-0.0833,  0.0739,  0.4328, -0.4983],\n",
            "        [-0.2717,  0.1680,  0.0793,  0.3052],\n",
            "        [ 0.4818,  0.3797,  0.4105, -0.1679]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0548,  0.0359,  0.0450,  0.0114, -0.3838, -0.2695, -0.3578, -0.1880,\n",
            "        -0.0905,  0.3191, -0.2822,  0.4940, -0.0786, -0.4205,  0.3716, -0.2590,\n",
            "         0.4025, -0.4664,  0.0714,  0.3014, -0.1227,  0.1155,  0.3531,  0.1745,\n",
            "         0.2852, -0.2965, -0.0442,  0.2865, -0.3169,  0.3618, -0.0333, -0.2425],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0947,  0.1371,  0.0004,  0.1308,  0.0363, -0.0269,  0.1001,  0.0218,\n",
            "         -0.0690, -0.0794,  0.1469,  0.1561,  0.1697, -0.1756, -0.0957, -0.0684,\n",
            "         -0.0950,  0.0711, -0.1470,  0.1606,  0.1314,  0.0710, -0.0043,  0.0781,\n",
            "         -0.0153, -0.0563,  0.0749,  0.0320, -0.0642, -0.1372,  0.0221, -0.1282],\n",
            "        [ 0.1167,  0.1336,  0.1337,  0.1348,  0.1292,  0.0770, -0.0009, -0.1175,\n",
            "          0.1725,  0.0339, -0.1163,  0.0532,  0.1004,  0.0158,  0.1516,  0.0305,\n",
            "          0.0101, -0.0868,  0.0404, -0.1051,  0.0770, -0.1654,  0.1715,  0.0273,\n",
            "          0.0869,  0.1624,  0.1060,  0.0009, -0.0284,  0.1451,  0.0299, -0.1326]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0664,  0.1371], device='cuda:0', requires_grad=True)\n",
            "0 Episode: Finished after 34 steps：10試行の平均step数 = 3.4\n",
            "1 Episode: Finished after 10 steps：10試行の平均step数 = 4.4\n",
            "2 Episode: Finished after 10 steps：10試行の平均step数 = 5.4\n",
            "3 Episode: Finished after 11 steps：10試行の平均step数 = 6.5\n",
            "4 Episode: Finished after 12 steps：10試行の平均step数 = 7.7\n",
            "5 Episode: Finished after 9 steps：10試行の平均step数 = 8.6\n",
            "6 Episode: Finished after 23 steps：10試行の平均step数 = 10.9\n",
            "7 Episode: Finished after 12 steps：10試行の平均step数 = 12.1\n",
            "8 Episode: Finished after 9 steps：10試行の平均step数 = 13.0\n",
            "9 Episode: Finished after 28 steps：10試行の平均step数 = 15.8\n",
            "10 Episode: Finished after 26 steps：10試行の平均step数 = 15.0\n",
            "11 Episode: Finished after 24 steps：10試行の平均step数 = 16.4\n",
            "12 Episode: Finished after 13 steps：10試行の平均step数 = 16.7\n",
            "13 Episode: Finished after 11 steps：10試行の平均step数 = 16.7\n",
            "14 Episode: Finished after 15 steps：10試行の平均step数 = 17.0\n",
            "15 Episode: Finished after 13 steps：10試行の平均step数 = 17.4\n",
            "16 Episode: Finished after 25 steps：10試行の平均step数 = 17.6\n",
            "17 Episode: Finished after 28 steps：10試行の平均step数 = 19.2\n",
            "18 Episode: Finished after 12 steps：10試行の平均step数 = 19.5\n",
            "19 Episode: Finished after 13 steps：10試行の平均step数 = 18.0\n",
            "20 Episode: Finished after 15 steps：10試行の平均step数 = 16.9\n",
            "21 Episode: Finished after 20 steps：10試行の平均step数 = 16.5\n",
            "22 Episode: Finished after 36 steps：10試行の平均step数 = 18.8\n",
            "23 Episode: Finished after 17 steps：10試行の平均step数 = 19.4\n",
            "24 Episode: Finished after 36 steps：10試行の平均step数 = 21.5\n",
            "25 Episode: Finished after 35 steps：10試行の平均step数 = 23.7\n",
            "26 Episode: Finished after 29 steps：10試行の平均step数 = 24.1\n",
            "27 Episode: Finished after 21 steps：10試行の平均step数 = 23.4\n",
            "28 Episode: Finished after 15 steps：10試行の平均step数 = 23.7\n",
            "29 Episode: Finished after 19 steps：10試行の平均step数 = 24.3\n",
            "30 Episode: Finished after 34 steps：10試行の平均step数 = 26.2\n",
            "31 Episode: Finished after 19 steps：10試行の平均step数 = 26.1\n",
            "32 Episode: Finished after 56 steps：10試行の平均step数 = 28.1\n",
            "33 Episode: Finished after 32 steps：10試行の平均step数 = 29.6\n",
            "34 Episode: Finished after 60 steps：10試行の平均step数 = 32.0\n",
            "35 Episode: Finished after 28 steps：10試行の平均step数 = 31.3\n",
            "36 Episode: Finished after 83 steps：10試行の平均step数 = 36.7\n",
            "37 Episode: Finished after 35 steps：10試行の平均step数 = 38.1\n",
            "38 Episode: Finished after 121 steps：10試行の平均step数 = 48.7\n",
            "39 Episode: Finished after 14 steps：10試行の平均step数 = 48.2\n",
            "40 Episode: Finished after 51 steps：10試行の平均step数 = 49.9\n",
            "41 Episode: Finished after 30 steps：10試行の平均step数 = 51.0\n",
            "42 Episode: Finished after 24 steps：10試行の平均step数 = 47.8\n",
            "43 Episode: Finished after 86 steps：10試行の平均step数 = 53.2\n",
            "44 Episode: Finished after 22 steps：10試行の平均step数 = 49.4\n",
            "45 Episode: Finished after 25 steps：10試行の平均step数 = 49.1\n",
            "46 Episode: Finished after 60 steps：10試行の平均step数 = 46.8\n",
            "47 Episode: Finished after 56 steps：10試行の平均step数 = 48.9\n",
            "48 Episode: Finished after 116 steps：10試行の平均step数 = 48.4\n",
            "49 Episode: Finished after 53 steps：10試行の平均step数 = 52.3\n",
            "50 Episode: Finished after 77 steps：10試行の平均step数 = 54.9\n",
            "51 Episode: Finished after 158 steps：10試行の平均step数 = 67.7\n",
            "52 Episode: Finished after 194 steps：10試行の平均step数 = 84.7\n",
            "53 Episode: Finished after 156 steps：10試行の平均step数 = 91.7\n",
            "54 Episode: Finished after 111 steps：10試行の平均step数 = 100.6\n",
            "55 Episode: Finished after 92 steps：10試行の平均step数 = 107.3\n",
            "56 Episode: Finished after 200 steps：10試行の平均step数 = 121.3\n",
            "57 Episode: Finished after 47 steps：10試行の平均step数 = 120.4\n",
            "58 Episode: Finished after 155 steps：10試行の平均step数 = 124.3\n",
            "59 Episode: Finished after 110 steps：10試行の平均step数 = 130.0\n",
            "60 Episode: Finished after 200 steps：10試行の平均step数 = 142.3\n",
            "61 Episode: Finished after 133 steps：10試行の平均step数 = 139.8\n",
            "62 Episode: Finished after 90 steps：10試行の平均step数 = 129.4\n",
            "63 Episode: Finished after 177 steps：10試行の平均step数 = 131.5\n",
            "64 Episode: Finished after 136 steps：10試行の平均step数 = 134.0\n",
            "65 Episode: Finished after 99 steps：10試行の平均step数 = 134.7\n",
            "66 Episode: Finished after 94 steps：10試行の平均step数 = 124.1\n",
            "67 Episode: Finished after 187 steps：10試行の平均step数 = 138.1\n",
            "68 Episode: Finished after 170 steps：10試行の平均step数 = 139.6\n",
            "69 Episode: Finished after 103 steps：10試行の平均step数 = 138.9\n",
            "70 Episode: Finished after 64 steps：10試行の平均step数 = 125.3\n",
            "71 Episode: Finished after 121 steps：10試行の平均step数 = 124.1\n",
            "72 Episode: Finished after 195 steps：10試行の平均step数 = 134.6\n",
            "73 Episode: Finished after 101 steps：10試行の平均step数 = 127.0\n",
            "74 Episode: Finished after 97 steps：10試行の平均step数 = 123.1\n",
            "75 Episode: Finished after 86 steps：10試行の平均step数 = 121.8\n",
            "76 Episode: Finished after 85 steps：10試行の平均step数 = 120.9\n",
            "77 Episode: Finished after 169 steps：10試行の平均step数 = 119.1\n",
            "78 Episode: Finished after 65 steps：10試行の平均step数 = 108.6\n",
            "79 Episode: Finished after 200 steps：10試行の平均step数 = 118.3\n",
            "80 Episode: Finished after 200 steps：10試行の平均step数 = 131.9\n",
            "81 Episode: Finished after 200 steps：10試行の平均step数 = 139.8\n",
            "82 Episode: Finished after 200 steps：10試行の平均step数 = 140.3\n",
            "83 Episode: Finished after 144 steps：10試行の平均step数 = 144.6\n",
            "84 Episode: Finished after 116 steps：10試行の平均step数 = 146.5\n",
            "85 Episode: Finished after 182 steps：10試行の平均step数 = 156.1\n",
            "86 Episode: Finished after 200 steps：10試行の平均step数 = 167.6\n",
            "87 Episode: Finished after 137 steps：10試行の平均step数 = 164.4\n",
            "88 Episode: Finished after 125 steps：10試行の平均step数 = 170.4\n",
            "89 Episode: Finished after 145 steps：10試行の平均step数 = 164.9\n",
            "90 Episode: Finished after 200 steps：10試行の平均step数 = 164.9\n",
            "91 Episode: Finished after 40 steps：10試行の平均step数 = 148.9\n",
            "92 Episode: Finished after 133 steps：10試行の平均step数 = 142.2\n",
            "93 Episode: Finished after 200 steps：10試行の平均step数 = 147.8\n",
            "94 Episode: Finished after 128 steps：10試行の平均step数 = 149.0\n",
            "95 Episode: Finished after 158 steps：10試行の平均step数 = 146.6\n",
            "96 Episode: Finished after 128 steps：10試行の平均step数 = 139.4\n",
            "97 Episode: Finished after 134 steps：10試行の平均step数 = 139.1\n",
            "98 Episode: Finished after 104 steps：10試行の平均step数 = 137.0\n",
            "99 Episode: Finished after 64 steps：10試行の平均step数 = 128.9\n",
            "100 Episode: Finished after 77 steps：10試行の平均step数 = 116.6\n",
            "101 Episode: Finished after 23 steps：10試行の平均step数 = 114.9\n",
            "102 Episode: Finished after 94 steps：10試行の平均step数 = 111.0\n",
            "103 Episode: Finished after 48 steps：10試行の平均step数 = 95.8\n",
            "104 Episode: Finished after 68 steps：10試行の平均step数 = 89.8\n",
            "105 Episode: Finished after 81 steps：10試行の平均step数 = 82.1\n",
            "106 Episode: Finished after 68 steps：10試行の平均step数 = 76.1\n",
            "107 Episode: Finished after 81 steps：10試行の平均step数 = 70.8\n",
            "108 Episode: Finished after 96 steps：10試行の平均step数 = 70.0\n",
            "109 Episode: Finished after 97 steps：10試行の平均step数 = 73.3\n",
            "110 Episode: Finished after 89 steps：10試行の平均step数 = 74.5\n",
            "111 Episode: Finished after 132 steps：10試行の平均step数 = 85.4\n",
            "112 Episode: Finished after 97 steps：10試行の平均step数 = 85.7\n",
            "113 Episode: Finished after 137 steps：10試行の平均step数 = 94.6\n",
            "114 Episode: Finished after 169 steps：10試行の平均step数 = 104.7\n",
            "115 Episode: Finished after 143 steps：10試行の平均step数 = 110.9\n",
            "116 Episode: Finished after 133 steps：10試行の平均step数 = 117.4\n",
            "117 Episode: Finished after 140 steps：10試行の平均step数 = 123.3\n",
            "118 Episode: Finished after 124 steps：10試行の平均step数 = 126.1\n",
            "119 Episode: Finished after 131 steps：10試行の平均step数 = 129.5\n",
            "120 Episode: Finished after 131 steps：10試行の平均step数 = 133.7\n",
            "121 Episode: Finished after 200 steps：10試行の平均step数 = 140.5\n",
            "122 Episode: Finished after 200 steps：10試行の平均step数 = 150.8\n",
            "123 Episode: Finished after 120 steps：10試行の平均step数 = 149.1\n",
            "124 Episode: Finished after 190 steps：10試行の平均step数 = 151.2\n",
            "125 Episode: Finished after 160 steps：10試行の平均step数 = 152.9\n",
            "126 Episode: Finished after 187 steps：10試行の平均step数 = 158.3\n",
            "127 Episode: Finished after 160 steps：10試行の平均step数 = 160.3\n",
            "128 Episode: Finished after 167 steps：10試行の平均step数 = 164.6\n",
            "129 Episode: Finished after 107 steps：10試行の平均step数 = 162.2\n",
            "130 Episode: Finished after 156 steps：10試行の平均step数 = 164.7\n",
            "131 Episode: Finished after 157 steps：10試行の平均step数 = 160.4\n",
            "132 Episode: Finished after 200 steps：10試行の平均step数 = 160.4\n",
            "133 Episode: Finished after 200 steps：10試行の平均step数 = 168.4\n",
            "134 Episode: Finished after 200 steps：10試行の平均step数 = 169.4\n",
            "135 Episode: Finished after 158 steps：10試行の平均step数 = 169.2\n",
            "136 Episode: Finished after 152 steps：10試行の平均step数 = 165.7\n",
            "137 Episode: Finished after 183 steps：10試行の平均step数 = 168.0\n",
            "138 Episode: Finished after 140 steps：10試行の平均step数 = 165.3\n",
            "139 Episode: Finished after 190 steps：10試行の平均step数 = 173.6\n",
            "140 Episode: Finished after 182 steps：10試行の平均step数 = 176.2\n",
            "141 Episode: Finished after 159 steps：10試行の平均step数 = 176.4\n",
            "142 Episode: Finished after 187 steps：10試行の平均step数 = 175.1\n",
            "143 Episode: Finished after 200 steps：10試行の平均step数 = 175.1\n",
            "144 Episode: Finished after 191 steps：10試行の平均step数 = 174.2\n",
            "145 Episode: Finished after 200 steps：10試行の平均step数 = 178.4\n",
            "146 Episode: Finished after 200 steps：10試行の平均step数 = 183.2\n",
            "147 Episode: Finished after 200 steps：10試行の平均step数 = 184.9\n",
            "148 Episode: Finished after 200 steps：10試行の平均step数 = 190.9\n",
            "149 Episode: Finished after 200 steps：10試行の平均step数 = 191.9\n",
            "150 Episode: Finished after 200 steps：10試行の平均step数 = 193.7\n",
            "151 Episode: Finished after 200 steps：10試行の平均step数 = 197.8\n",
            "152 Episode: Finished after 200 steps：10試行の平均step数 = 199.1\n",
            "153 Episode: Finished after 200 steps：10試行の平均step数 = 199.1\n",
            "154 Episode: Finished after 200 steps：10試行の平均step数 = 200.0\n",
            "10回連続成功\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "155 Episode: Finished after 200 steps：10試行の平均step数 = 200.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdMAAAE8CAYAAACb7Fv6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAG+ElEQVR4nO3cMYtdaRnA8edMJtlZjZsIWUVIYeEuEl1s7CxMYRUkiKUgfoe0poulnyCfwMbO2gyTQhRsLVKYQUQFV0XJJJlk5l6LZQVZZrLO37thlt+vvO+553m7P/dyzrus1+sBAM5u63VvAADOOzEFgEhMASASUwCIxBQAIjEFgGj7FevemwGADywnLfhlCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAETbr3sDAFCs1+t58eTvM+vVidds73xuLlza2dgexBSAc+93P//JHB0enLj+5W//aN7+6rc2Nt/fvAAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKANGyXq9PWz91EQD+Hw4PD+fOnTtzfHz8P393WWZ+8PXV7GyffM3DPyzz6G/LmfZ2+/btuXXr1szMiTc4ZTQAfDKOjo7m/v37c3R0dKbvf/+nP5ydyzsnrj94sDu/+NWjM937+vXrH8b0RGIKwKfG0+PLc3B8ddbrrbm49XyubL8/W8tq43PFFIBPhX+8/OI8evrN+efLt2c127Oz9WS+9Mbv593P/Gbjs8UUgHPvydHn59GL78zh6rP/+ezZ6q15/Oy9Wc3WrObhRud7mheAc+/X//ruf4X0Q+u5MPvP3ps/H35lo/PFFIDzb33ak7rLnP7iSiemABCJKQDn3pWLfz1x7Y3lYHYuPN3ofDEF4Nz7xuVfzhcu7X/k8+3lcL52+eFcu/jHjc73NC8A597q+GDeefPBXFzdmD89f3eO1pfmre335503fztXlr/M8Wqz75qeGtPd3d2NDgeAmZnnz5/PK463PdX3fvyzWZZl1jOzXi8zs8wy61mWD+5ZYvr48ePZ3d2dmzdvnnjNqTHd29s783AA+LhevHiRYnq8Ws+mjpPf39+fvb29U2PqoHsAXruDg4O5evXqmc/m3aR79+7N3bt3Z0456N4DSAAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQOegegNdua2trbty4MS9fvnzdW/mIa9euvfIaxwkCwMfjOEEA2BQxBYBITAEgElMAiMQUACIxBYBITAEgElMAiMQUACIxBYBITAEgElMAiMQUACIxBYBITAEgElMAiMQUACIxBYBITAEgElMAiMQUACIxBYBITAEgElMAiMQUACIxBYBITAEgElMAiMQUACIxBYBITAEgElMAiMQUACIxBYBITAEgElMAiMQUACIxBYBITAEgElMAiMQUACIxBYBITAEgElMAiMQUACIxBYBITAEgElMAiMQUACIxBYBITAEgElMAiMQUACIxBYBITAEgElMAiMQUACIxBYBITAEgElMAiMQUACIxBYBITAEg2n7F+vKJ7AIAzjG/TAEgElMAiMQUACIxBYBITAEgElMAiP4NkJm1/wvyVu4AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}